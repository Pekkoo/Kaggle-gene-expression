{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle-kilpailu: Gene Expression Prediction\n",
    "### Pekko Ojanen, [pekkoo](https://www.kaggle.com/pekkoo) @ Kaggle\n",
    "https://inclass.kaggle.com/c/gene-expression-prediction\n",
    "\n",
    "## Taustaa\n",
    "Kilpailu järjestettiin osana TTY:n SGN-41007 Pattern Recognition and Machine Learning -kurssia ja se oli avoinna myös kurssin ulkopuolelle. Tavoitteena oli ennustaa geeniekspressiotaso histonimuokkaussignaalien pohjalta. Geeniekspressiotasoja oli kaksi, korkea ja matala, joten kyseessä oli binäärinen luokitteluongelma. Kilpailun arviointikriteerinä toimi Area Under Curve (AUC), joten ennusteiden tuli olla korkean geeniekspressiotason todennäköisyyksiä.\n",
    "\n",
    "Ryhmäämme \"Group 40\" kuuluivat lisäkseni Inkariina Simola ja Bahareh Darvishmohammadi. Päädyimme sijalle **4/125**. Jaoimme työt ryhmän kesken suurin piirtein siten, että Inkariina teki data-analyysia ja visualisointia etsien uusia featureita, Bahareh kokeili muutamia scikit-learniin implementoituja algoritmeja ja minä keskityin tunkkaamaan XGBoostia, neuroverkkoja sekä näistä ja muutamasta muusta mallista koostuvaa lopullista ensembleä.\n",
    "\n",
    "Tässä raportissa esittelen vaihe vaiheelta siistityn koodini, mikä tuottaa neljännelle sijalle asettuvan ratkaisun ongelmaan. Suuri osa eksperimentoinnista on poistettu, jottei raportti olisi loputtoman pitkä. Myös koodisolujen tulosteet on poistettu, sillä kilpailun tuiskeessa soluja ajettiin epämääräisessä järjestyksessä, jolloin tulosteet olivat lopulta keskenään ristiriidassa.  Raportti etenee luontevasti datan esikäsittelystä ja featureiden luomisesta kohti lopullisen ensemblen syntymistä. Lopuksi pohditaan mitä kilpailusta opittiin ja mitä olisi kenties voinut tehdä paremmin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Koodi\n",
    "\n",
    "Aluksi ladataan tarvittavat kirjastot ja tehdään muutamia asetuksia, jotka varmistavat tulosten toistettavuuden tai säätävät tulostuksia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "import xgboost as xgb\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, LSTM\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Asetukset\n",
    "pd.options.display.max_columns = 999\n",
    "np.random.seed(123)\n",
    "random_state = 2017\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Määritetään funktiot datan lataamiseen, skaalaamiseen sekä neuroverkkojen rakentamiseen. \n",
    "\n",
    "Funktio **load_data** tarjottiin professori Heikki Huttusen puolesta kilpailun foorumilla ja sitä on muokattu vain tekemällä datan uudelleenmuotoilu valinnaiseksi. Muokkaus johtuu siitä, että ratkaisussamme dataa tarvitaan kahdessa eri muodossa riippuen siitä syötetäänkö sitä neuroverkoille vai ei.\n",
    "\n",
    "Neuroverkkojen arkkitehtuuri ja hyperparametrit etsittiin manuaalisesti kokeilemalla ja hieman [DeepChrome-arkkitehtuurista](https://arxiv.org/abs/1607.02078) inspiroituen. Kokeilua hankaloitti huomattavasti se, että neuroverkkoja pyöritettiin läppärillä ilman kunnollista näytönohjainta. Tämä oli melko hidasta ja uskoisin, että kunnollisella laskentateholla oltaisiin päädytty ainakin hieman erilaiseen lopputulokseen.\n",
    "\n",
    "Funktio **rnn_model** rakentaa CNN+RNN-yhdistelmän, mikä saattaa näin jälkikäteen mietittynä olla tarpeettoman monimutkaista, sillä se toimii suunnilleen yhtä hyvin kuin pelkkä CNN-malli. Toisaalta se sisältää huomattavasti vähemmän parametreja kuin pelkkä CNN, mikä on suotavaa etenkin tässä tilanteessa, kun koulutusdataa ei ole kovin paljoa (15 485 observaatiota)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(ravel=True):\n",
    "    print(\"Loading data...\")\n",
    "    x_train = np.loadtxt(\"x_train.csv\", delimiter = \",\", skiprows = 1)\n",
    "    x_test  = np.loadtxt(\"x_test.csv\", delimiter = \",\", skiprows = 1)    \n",
    "    y_train = np.loadtxt(\"y_train.csv\", delimiter = \",\", skiprows = 1)\n",
    "    \n",
    "    print(\"All files loaded. Preprocessing...\")\n",
    "\n",
    "    # remove the first column(Id)\n",
    "    x_train = x_train[:,1:]\n",
    "    x_test  = x_test[:,1:]\n",
    "    y_train = y_train[:,1:]\n",
    "\n",
    "    # Every 100 rows correspond to one gene.\n",
    "    # Extract all 100-row-blocks into a list using np.split.\n",
    "    num_genes_train = x_train.shape[0] / 100\n",
    "    num_genes_test  = x_test.shape[0] / 100\n",
    "\n",
    "    print(\"Train / test data has %d / %d genes.\" % \\\n",
    "          (num_genes_train, num_genes_test))\n",
    "\n",
    "    x_train = np.split(x_train, num_genes_train)\n",
    "    x_test  = np.split(x_test, num_genes_test)\n",
    "\n",
    "    if ravel:\n",
    "        # Reshape by raveling each 100x5 array into a 500-length vector\n",
    "        x_train = [g.ravel() for g in x_train]\n",
    "        x_test  = [g.ravel() for g in x_test]\n",
    "    \n",
    "    # convert data from list to array\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    x_test  = np.array(x_test)\n",
    "    y_train = np.ravel(y_train)\n",
    "    \n",
    "    # Now x_train should be 15485 x 500 and x_test 3871 x 500.\n",
    "    # y_train is 15485-long vector.\n",
    "    \n",
    "    print(\"x_train shape is %s\" % str(x_train.shape))    \n",
    "    print(\"y_train shape is %s\" % str(y_train.shape))\n",
    "    print(\"x_test shape is %s\" % str(x_test.shape))\n",
    "    print('Data preprocessing done...')\n",
    "    \n",
    "    return(x_train, y_train, x_test)\n",
    "\n",
    "def minmax_scale(array, minimum=0, maximum=1):\n",
    "    array_std = (array - array.min(axis=0)) / (array.max(axis=0) - array.min(axis=0))\n",
    "    return array_std * (maximum - minimum) + minimum\n",
    "\n",
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution1D(nb_filter=50, filter_length=10, border_mode='same',\n",
    "                            input_shape=(100, 5)))\n",
    "    model.add(PReLU())\n",
    "    model.add(MaxPooling1D(5, border_mode='same'))\n",
    "    model.add(Dropout(.3))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(PReLU())\n",
    "    model.add(Dropout(.3))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(100))\n",
    "    model.add(PReLU())\n",
    "    model.add(Dropout(.3))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def rnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution1D(nb_filter=50, filter_length=10, border_mode='same',\n",
    "                            input_shape=(100, 5)))\n",
    "    model.add(PReLU())\n",
    "    model.add(MaxPooling1D(5, border_mode='same'))\n",
    "    model.add(Dropout(.4))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(.4))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(125))\n",
    "    model.add(PReLU())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datan esikäsittely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ladataan data 15485 x 500 -muodossa ja muutetaan dataframeiksi featureiden käsittelyn ja lisäämisen helpottamiseksi *pandas*-kirjaston avulla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_test = load_data()\n",
    "x_train_df = pd.DataFrame(x_train)\n",
    "x_test_df = pd.DataFrame(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ladataan data erikseen neuroverkoille soveltuvassa muodossa. Tällä kertaa muoto pysyy alkuperäisenä eikä tarvetta ole käsitellä featureita tai muuntaa dataa matriiseista dataframeiksi, sillä neuroverkkomme löytävät sopivat featuret itse. Neuroverkkojen oppimisen jouhevoittamiseksi data skaalataan välille 0 - 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_100_5, y_train, x_test_100_5 = load_data(ravel=False)\n",
    "x_train_100_5 = minmax_scale(x_train_100_5)\n",
    "x_test_100_5 = minmax_scale(x_test_100_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luodaan funktio, mikä laskee statistiikkoja eri \"markereille\". Markerit esiintyvät dataframen kolumneissa viiden välein. Paljon muitakin statistiikkoja kokeiltiin (esim. mediaani, varianssi, minimi/maksimi ja summat), mutta nämä kolme muodostivat cross-validation-proseduurin perusteella parhaan joukon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stats(row, index=0, stat='mean'):\n",
    "    if stat == 'mean':\n",
    "        return row[index:500:5].mean()\n",
    "    elif stat == 'perc0': # Nollien prosentuaalinen osuus markerille\n",
    "        return np.mean(row[index:500:5] == 0)\n",
    "    elif stat == 'std':\n",
    "        return np.std(row[index:500:5])\n",
    "    else:\n",
    "        raise ValueError(stat + ' currently not supported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyödyntäen funktiota yllä, luodaan kolumnit jokaiselle markerille jokaisesta statistiikasta sekä koulutus- että testausdataframeille."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "markers = ['H3K4me3', 'H3K4me1', 'H3K36me3', 'H3K9me3', 'H3K27me3']\n",
    "dataframes = [x_train_df, x_test_df]\n",
    "stats = ['mean', 'perc0', 'std']\n",
    "\n",
    "for df in dataframes:\n",
    "    for stat in stats:\n",
    "        for i, j in enumerate(markers):\n",
    "            df[j + '_' + stat] = df.apply(get_stats, args=(i, stat), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ennustavien mallien rakentaminen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luodaan DMatrix XGBoostia varten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xg_train = xgb.DMatrix(x_train_df, label=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etsitään optimaalisia hyperparametreja XGBoostille Bayesilaisen optimoinnin avulla. Koodi on napattu käytännössä suoraan BayesianOptimization-kirjaston [Github-esimerkistä](https://github.com/fmfn/BayesianOptimization/blob/master/examples/xgboost_example.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgb_evaluate(min_child_weight,\n",
    "                 colsample_bytree,\n",
    "                 max_depth,\n",
    "                 subsample,\n",
    "                 gamma,\n",
    "                 alpha):\n",
    "\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['colsample_bytree'] = max(min(colsample_bytree, 1), 0)\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['subsample'] = max(min(subsample, 1), 0)\n",
    "    params['gamma'] = max(gamma, 0)\n",
    "    params['alpha'] = max(alpha, 0)\n",
    "\n",
    "    cv_result = xgb.cv(params, xg_train, num_boost_round=num_rounds, \n",
    "                       nfold=5, seed=random_state, stratified=True, \n",
    "                       metrics='auc', callbacks=[xgb.callback.early_stop(100)])\n",
    "\n",
    "    return cv_result['test-auc-mean'].values[-1]\n",
    "\n",
    "\n",
    "num_rounds = 3000\n",
    "num_iter = 120\n",
    "init_points = 5\n",
    "params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eta': .01,\n",
    "        'silent': 1,\n",
    "        'verbose_eval': True,\n",
    "        'seed': random_state\n",
    "    }\n",
    "\n",
    "xgbBO = BayesianOptimization(xgb_evaluate, {'min_child_weight': (1, 20),\n",
    "                                            'colsample_bytree': (.1, 1),\n",
    "                                            'max_depth': (1, 40),\n",
    "                                            'subsample': (.6, 1),\n",
    "                                            'gamma': (0, 8),\n",
    "                                            'alpha': (0, 8),\n",
    "                                            })\n",
    "\n",
    "xgbBO.maximize(init_points=init_points, n_iter=num_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alla parhaat löydetyt hyperparametrit. Puista tuli huomattavan syviä."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_params3 = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eta': .01,\n",
    "    'alpha': 0.9939,\n",
    "    'colsample_bytree': .1066,\n",
    "    'gamma': 1.8422,\n",
    "    'max_depth': 39,\n",
    "    'min_child_weight': 7,\n",
    "    'subsample': .8101,\n",
    "    'seed': random_state,\n",
    "    'silent': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rullataan XGBoostin oma cross-validation-proseduuri löydetyillä parametreilla, jolloin saadaan optimaalinen puiden lukumäärä."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_cv = xgb.cv(bayes_params_3, xg_train, num_boost_round=10000, early_stopping_rounds=200, nfold=5,\n",
    "                stratified=True, verbose_eval=True, metrics='auc', seed=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luodaan meta-versio koulutus- ja testausdataframeista ensemblen rakentamista varten. Lisätään näihin tyhjät kolumnit kaikille käytettäville malleille. Ensemble rakennetaan [Kagglen blogissa julkaistun ohjeen](http://blog.kaggle.com/2016/12/27/a-kagglers-guide-to-model-stacking-in-practice/) mukaisesti. Lopulliset käytettävät mallit valikoitiin rakentamalla erilaisia ensemblejä ja cross-validoimalla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_df_meta = x_train_df.copy()\n",
    "x_train_df_meta['XGB'] = np.nan\n",
    "x_train_df_meta['CNN'] = np.nan\n",
    "x_train_df_meta['RNN'] = np.nan\n",
    "x_train_df_meta['LR'] = np.nan\n",
    "x_train_df_meta['ET'] = np.nan\n",
    "x_train_df_meta['RF'] = np.nan\n",
    "\n",
    "x_test_df_meta = x_test_df.copy()\n",
    "x_test_df_meta['XGB'] = np.nan\n",
    "x_test_df_meta['CNN'] = np.nan\n",
    "x_test_df_meta['RNN'] = np.nan\n",
    "x_test_df_meta['LR'] = np.nan\n",
    "x_test_df_meta['ET'] = np.nan\n",
    "x_test_df_meta['RF'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tehdään lista ensemblessä käytettävistä scikit-learn-algoritmeista ja niille annettavista nimistä. Jokaisen mallin hyperparametrit valittiin yksittäin cross-validoiden koulutusdatalla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clfs = [LogisticRegression(C=.01, penalty='l1'),\n",
    "       ExtraTreesClassifier(n_estimators=800, n_jobs=2),\n",
    "       RandomForestClassifier(n_estimators=800, n_jobs=2, criterion='entropy')]\n",
    "\n",
    "clf_names = ['LR', 'ET', 'RF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sitten rakennetaan itse ensemble. Koulutusdata jaetaan viiteen osaan ja jokaisella kierroksella koulutetaan mallit neljällä osalla sekä ennustetaan korkean geeniekspressiotason todennäköisyydet viidennelle. Näitä ennustuksia tallennetaan jokaisella kierroksella koulutusdatan meta-version tietyille riveille, josta niitä myöhemmin käytetään koulutusdatana seuraavan tason mallissa.\n",
    "\n",
    "Optimaalinen epochien määrä neuroverkoille tuntui vaihtelevan merkittävästi, joten mallit päädyttiin tallentamaan jokaiselta epochilta ja testaamaan niitä kaikkia kunkin kierroksen validointidatalla. Parhaat pisteet saava malli valittiin ja muut poistettiin. Tämä saattoi tarpeettomasti lisätä monimutkaisuutta, enkä ole varma oliko se nerokasta vai typerää.\n",
    "\n",
    "Ensemblen rakentaminen kesti läppärilläni noin 14 tuntia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_fold = 0\n",
    "n_epochs = 25\n",
    "\n",
    "CNN_test_preds = []\n",
    "RNN_test_preds = []\n",
    "\n",
    "neural_nets = ['CNN', 'RNN']\n",
    "\n",
    "for train_index, test_index in cv.split(x_train_df, y_train):\n",
    "    \n",
    "    # Valitaan data sekä neuroverkoille että muille käytettäville malleille\n",
    "    X_cvtrain = x_train_df.iloc[train_index]\n",
    "    X_cvtest = x_train_df.iloc[test_index]\n",
    "    X_cvtrain_100_5 = x_train_100_5[train_index]\n",
    "    X_cvtest_100_5 = x_train_100_5[test_index]\n",
    "    y_cvtrain = y_train[train_index]\n",
    "    y_cvtest = y_train[test_index]\n",
    "    \n",
    "    num_fold += 1\n",
    "    \n",
    "    # Valmiiksi oltiin luotu viisi kansiota hakemistoon, yksi kutakin kierrosta varten\n",
    "    os.chdir('/Users/peks/Documents/Studies/ML/Competition/Keras_models/Fold' + str(num_fold))\n",
    "    \n",
    "    # Koulutetaan molemmat neuroverkot loopissa, CNN ja CNN+RNN\n",
    "    for net in neural_nets:\n",
    "        if net == 'CNN':\n",
    "            model = cnn_model()\n",
    "        else:\n",
    "            model = rnn_model()\n",
    "            \n",
    "        # Tallennetaan malli jokaiselta epochilta hakemistoon\n",
    "        callbacks = [\n",
    "            ModelCheckpoint(filepath='weights.-{epoch:02d}-{val_acc:.4f}.hdf5', monitor='val_acc')\n",
    "        ]\n",
    "        \n",
    "        # Sovitetaan malli\n",
    "        model.fit(X_cvtrain_100_5, y_cvtrain, validation_data=[X_cvtest_100_5, y_cvtest],\n",
    "                  nb_epoch=n_epochs, callbacks=callbacks, batch_size=16)\n",
    "        \n",
    "        # Haetaan jokaisen epochin mallien nimet\n",
    "        fold_model_names = os.listdir()[1:]\n",
    "        epoch_aucs = np.array([])\n",
    "        \n",
    "        # Testataan jokaisen epochin mallia validointidatalla ja lisätään AUC-pisteytys listaan\n",
    "        for epoch_model in fold_model_names:\n",
    "            model.load_weights(epoch_model)\n",
    "            epoch_auc = roc_auc_score(y_cvtest, model.predict(X_cvtest_100_5).ravel())\n",
    "            epoch_aucs = np.append(epoch_aucs, epoch_auc)\n",
    "        \n",
    "        # Valitaan malleista parhaiten validointidatalla toimiva ja ladataan sen painotukset\n",
    "        model.load_weights(fold_model_names[epoch_aucs.argmax()])\n",
    "        \n",
    "        # Poistetaan tallennetut epoch-mallit\n",
    "        for file in fold_model_names:\n",
    "            os.remove(file)\n",
    "        \n",
    "        # Ennustetaan sekä validointidatalla koulutus-metaa varten että \n",
    "        # testidatalla testi-metaa varten\n",
    "        nn_fold_pred = model.predict(X_cvtest_100_5).ravel()\n",
    "        x_train_df_meta.loc[test_index, net] = nn_fold_pred\n",
    "        nn_test_pred = model.predict(x_test_100_5).ravel()\n",
    "        \n",
    "        # Listään testidatan ennusteet oikeaan listaan\n",
    "        if net == 'CNN':\n",
    "            CNN_test_preds.append(nn_test_pred)\n",
    "        else:\n",
    "            RNN_test_preds.append(nn_test_pred)\n",
    "        \n",
    "        # Tulostetaan kierroksen tulokset validointidatalla neuroverkoille\n",
    "        print('Fold', num_fold, net, 'CV AUC:', roc_auc_score(y_cvtest, nn_fold_pred))\n",
    "        \n",
    "    # Rullataan scikit-learn mallit läpi ja ennustetaan jokaisella\n",
    "    for i, clf in enumerate(clfs):\n",
    "        clf.fit(X_cvtrain, y_cvtrain)\n",
    "        clf_pred = clf.predict_proba(X_cvtest)[:, 1]\n",
    "        x_train_df_meta.loc[test_index, clf_names[i]] = clf_pred\n",
    "        \n",
    "        print('Fold', num_fold, clf_names[i], 'CV AUC:', roc_auc_score(y_cvtest, clf_pred))\n",
    "    \n",
    "    # Koulutetaan XGBoost-malli aiemmin löydetyillä parametreilla\n",
    "    xg_cvtrain = xgb.DMatrix(X_cvtrain, label=y_cvtrain)\n",
    "    xg_cvtest = xgb.DMatrix(X_cvtest)\n",
    "    \n",
    "    xgb_model = xgb.train(bayes_params3, xg_cvtrain, num_boost_round=1184)\n",
    "    xgb_cvpred = xgb_model.predict(xg_cvtest)\n",
    "    x_train_df_meta.loc[test_index, 'XGB'] = xgb_cvpred\n",
    "    print('Fold', num_fold, 'XGB CV AUC:', roc_auc_score(y_cvtest, xgb_cvpred))\n",
    "    \n",
    "    print('Fold', num_fold, 'completed.')\n",
    "    print(50 * '-')\n",
    "\n",
    "print('Train meta filled. Thank you.')\n",
    "os.chdir('/Users/peks/Documents/Studies/ML/Competition/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tallennetaan tämänhetkinen koulutus-meta-dataframe CSV-tiedostoon varmuuden vuoksi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_df_meta.to_csv('train_meta.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tarkistetaan CV-pisteet sovittamalla logistinen regressio meta-ennusteiden päälle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LR = LogisticRegression()\n",
    "used_cols = ['XGB', 'CNN', 'RNN', 'LR', 'ET', 'RF']\n",
    "\n",
    "cross_val_score(LR, x_train_df_meta[used_cols], y_train, scoring='roc_auc', cv=cv).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutkitaan josko parantamisen varaa löytyisi lisäämällä alkuperäisiä marker-statistiikkoihin liittyviä featureita. Pyörittelemällä tätä hetken aikaa eri kombinaatioilla saatiin CV-pisteitä nostettua hieman."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stat_cols = x_train_df_meta.columns[500:-7].values\n",
    "used_cols = ['XGB', 'CNN', 'RNN', 'LR', 'ET','H3K27me3_std', \n",
    "             'H3K27me3_mean', 'H3K4me1_perc0', 'H3K9me3_std']\n",
    "\n",
    "print('Baseline:', cross_val_score(LR, x_train_df_meta[used_cols], \n",
    "                      y_train, scoring='roc_auc', cv=cv).mean())\n",
    "\n",
    "# Printataan uudet CV-pisteet featureita yksi kerrallaan lisäillen\n",
    "for i in range(len(stat_cols)):\n",
    "    print(stat_cols[i], cross_val_score(LR, x_train_df_meta[used_cols + [stat_cols[i]]],\n",
    "                                        y_train, scoring='roc_auc', cv=cv).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aivan kilpailun viime hetkillä päätin testata vielä XGBoost-mallien rakentamista eri seedeillä ja näistä keskiarvon ottamista. Tämä paransi tulostamme vielä yllättävän paljon. Jos tämän olisi tajunnut tehdä aikaisemmin, olisin nostanut loopattavien seedien lukumäärää vielä hieman. Nyt tuli kiire niin piti rajoittaa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgbs = []\n",
    "xg_train = xgb.DMatrix(x_train_df, label=y_train)\n",
    "xg_test = xgb.DMatrix(x_test_df)\n",
    "\n",
    "for i in range(1, 8):\n",
    "    complete_xgb_model = xgb.train(bayes_params3, xg_train, num_boost_round=int(1184/.8))\n",
    "    xgb_pred = complete_xgb_model.predict(xg_test)\n",
    "    xgbs.append(xgb_pred)\n",
    "    \n",
    "x_test_df_meta['XGB'] = np.mean(xgbs, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tehdään lopulliset yksittäisennusteet muilla scikit-learn-malleilla testidatalle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_clfs = [LogisticRegression(C=.01, penalty='l1'),\n",
    "              ExtraTreesClassifier(n_estimators=800, n_jobs=2)]\n",
    "final_clf_names = ['LR', 'ET']\n",
    "\n",
    "x_test_df_meta.drop('RF', axis=1, inplace=True) # Random forest huomattiin haitalliseksi ensemblessä\n",
    "x_test_df_meta['CNN'] = np.mean(CNN_test_preds, axis=0)\n",
    "x_test_df_meta['RNN'] = np.mean(RNN_test_preds, axis=0)\n",
    "\n",
    "for i, clf in enumerate(final_clfs):\n",
    "    clf.fit(x_train_df, y_train)\n",
    "    x_test_df_meta[final_clf_names[i]] = clf.predict_proba(x_test_df)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viimeisen tason mallina meta-featureiden päällä käytetään jälleen XGBoostia, jolle etsitään taas optimaalisia hyperparametreja Bayesilaisella optimoinnilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xg_train_meta = xgb.DMatrix(x_train_df_meta[used_cols], label=y_train)\n",
    "xg_test_meta = xgb.DMatrix(x_test_df_meta[used_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def xgb_evaluate(min_child_weight,\n",
    "                 colsample_bytree,\n",
    "                 max_depth,\n",
    "                 subsample,\n",
    "                 gamma,\n",
    "                 alpha):\n",
    "\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['colsample_bytree'] = max(min(colsample_bytree, 1), 0)\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['subsample'] = max(min(subsample, 1), 0)\n",
    "    params['gamma'] = max(gamma, 0)\n",
    "    params['alpha'] = max(alpha, 0)\n",
    "\n",
    "    cv_result = xgb.cv(params, xg_train_meta, num_boost_round=num_rounds, \n",
    "                       nfold=5, seed=random_state, stratified=True, \n",
    "                       metrics='auc', callbacks=[xgb.callback.early_stop(100)])\n",
    "\n",
    "    return cv_result['test-auc-mean'].values[-1]\n",
    "\n",
    "\n",
    "num_rounds = 3000\n",
    "num_iter = 120\n",
    "init_points = 5\n",
    "params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eta': .01,\n",
    "        'silent': 1,\n",
    "        'verbose_eval': True,\n",
    "        'seed': random_state\n",
    "    }\n",
    "\n",
    "xgbBO = BayesianOptimization(xgb_evaluate, {'min_child_weight': (1, 20),\n",
    "                                            'colsample_bytree': (.1, 1),\n",
    "                                            'max_depth': (1, 40),\n",
    "                                            'subsample': (.6, 1),\n",
    "                                            'gamma': (0, 8),\n",
    "                                            'alpha': (0, 8),\n",
    "                                            })\n",
    "\n",
    "xgbBO.maximize(init_points=init_points, n_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_params_final = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eta': .01,\n",
    "    'alpha': .0748,\n",
    "    'colsample_bytree': .8819,\n",
    "    'gamma': .8596,\n",
    "    'max_depth': 1,\n",
    "    'min_child_weight': 2,\n",
    "    'subsample': .6542,\n",
    "    'seed': random_state,\n",
    "    'silent': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyvät parametrit on löydetty, joten on aika tehdä lopulliset ennusteet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_xgb_ = xgb.train(bayes_params_final, xg_train_meta, num_boost_round=int(912/.8))\n",
    "xgb_pred = final_xgb_model.predict(xg_test_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luodaan data frame geenitunnisteista ja lopullisista ennusteista. Tallennetaan tämä CSV-tiedostona ja lähetetään kilpailuun. Lopullinen AUC-pisteytys on 0.92787 Kagglen yksityisellä pistetaululla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'GeneId': np.arange(1, x_test.shape[0] + 1), \n",
    "                        'Prediction': xgb_pred})\n",
    "pred_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mietteitä\n",
    "\n",
    "Opin kilpailussa todella paljon ja osallistuminen oli lystiä. Ensimmäistä kertaa rakensin kunnon ensemblen, käytin Bayesilaista optimointia hyperparametrien löytämiseksi sekä käytin neuroverkkoja Kaggle-kilpailussa. Nähdäkseni parantamisen varaa jäi etenkin neuroverkkojen hyödyntämisen suhteen, sillä esimerkiksi [Kagglen foorumiketjussa](https://inclass.kaggle.com/c/gene-expression-prediction/forums/t/29637/congratulations-to-the-winners) toiseksi tulleet kertoivat käyttäneensä pelkästään CNN:ää, ottaen mediaanin 10-osaisen cross-validation-proseduurin ennusteista testidatalle. Neuroverkkojen tutkimista rajoitti kuitenkin pelkkä läppärin käyttö. Kaksi erilaista neuroverkkomallia tuli silti rakennettua, mikä oli luultavasti hieman ylitseampuvaa, vaikka se ensembleä tässä vähän kohensikin.\n",
    "\n",
    "Parempien neuroverkkoarkkitehtuurien lisäksi olen lähes varma, että 10-osainen cross-validation olisi nostanut pisteitämme nykyisilläkin malleilla. Erityisesti se olisi uskoakseni hyödyttänyt juurikin neuroverkkoja, jotka olisivat nauttineet kasvaneesta koulutusdatan määrästä, ja joiden ennusteet testidatalla luotiin nimenomaan cross-validation-proseduurin aikana. Laskentatehon puutteen vuoksi käytin vain viittä osaa ristiinvalidoidessa. Myös XGBoostin seedejä olisi voinut rullata enemmän läpi, jos olisi sen aikasemmin tajunnut tehdä.\n",
    "\n",
    "Neljänteen sijaan voi kuitenkin olla sangen tyytyväinen. Ero kolmanneksi ja toiseksi sijoittuneisiin joukkueisiin jäi pieneksi. Kilpailun voittaja sen sijaan paini täysin omassa sarjassaan. Ero muihin oli niinkin suuri, että haistelisimme voittajan löytäneen internetistä [oikeat vastaukset testidatalle](http://egg2.wustl.edu/roadmap/data/byDataType/rna/expression/)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
